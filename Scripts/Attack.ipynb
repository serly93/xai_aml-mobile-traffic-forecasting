{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ac324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the centered cell\n",
    "from utils import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\" # Set the gpu card number to use. Use this line if your machine has multiple gpu cards.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or '3' for FATAL logs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nr = 5 # grid size of nr*nr\n",
    "Capacity_forecasting = 1 # 1: Capacity forecasting, 0: traffic forecasting\n",
    "lookback = 3 # history length\n",
    "alpha = 0.1 # calibration parameter for capacity forecasting\n",
    "\n",
    "if Capacity_forecasting == 1:\n",
    "    damage = 'capacity_forecasting'\n",
    "    loss_func = cost_func_more_args(alpha)\n",
    "else:\n",
    "    damage = 'mae'\n",
    "    loss_func = mae\n",
    "\n",
    "cell = 5355 # select the center cell to perform the attack in the 5*5 grid around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepCog architecture from: https://github.com/wnlUc3m/deepcog\n",
    "sample_shape = (nr, nr)\n",
    "batch_size = 128\n",
    "num_cluster = 1\n",
    "no_epochs = 150\n",
    "validation_split = 0.2\n",
    "verbosity = 1\n",
    "#steps_per_epoch = 40\n",
    "neurons = 32\n",
    "ker_sz = 3\n",
    "\n",
    "def make_nn_model(load_input_shape, lookback, num_cluster):\n",
    "    '''Build DeepCog architecture'''\n",
    "    inputs = tf.keras.layers.Input(shape=(\n",
    "        lookback,  load_input_shape[0],load_input_shape[1],  1))\n",
    "    x = tf.keras.layers.Conv3D(neurons, kernel_size = (ker_sz, ker_sz, ker_sz), activation = 'relu', padding = 'same', name = 'block1_conv1')(inputs)\n",
    "    x = tf.keras.layers.Conv3D(neurons, kernel_size = (ker_sz * 2, ker_sz * 2, ker_sz * 2), activation = 'relu', padding = 'same')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Conv3D(neurons / 2, kernel_size=(ker_sz * 2,ker_sz * 2, ker_sz * 2), activation = 'relu', padding = 'same')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(neurons * 2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(neurons, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(num_cluster)(x)\n",
    "    model = Model(inputs = inputs, outputs = output)\n",
    "    if Capacity_forecasting == False:\n",
    "        model.compile(optimizer = Adam(0.0005), loss = mae)\n",
    "    else:\n",
    "        model.compile(optimizer = Adam(0.0005), loss = cost_func_more_args(alpha))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and models\n",
    "\n",
    "nn = make_nn_model(sample_shape, lookback, num_cluster)\n",
    "if Capacity_forecasting == True:\n",
    "    nn = tf.keras.models.load_model('../Trained_models/'+str(damage)+'/Models/mymodel_%d.h5' %cell,\n",
    "                                    custom_objects = {'loss': cost_func_more_args}, compile = False)\n",
    "else:\n",
    "    nn = tf.keras.models.load_model('../Trained_models/'+str(damage)+'/Models/mymodel_%d.h5' %cell,\n",
    "                                    custom_objects = {'loss': mae}, compile = False)\n",
    "    \n",
    "test = np.load('../Trained_models/'+str(damage)+'/Data/test_'+ str(cell)+'.npy')\n",
    "\n",
    "ds = []\n",
    "ds2 = []\n",
    "tmp = []\n",
    "tmp2 = []\n",
    "\n",
    "ds= tf.keras.preprocessing.timeseries_dataset_from_array(test, targets = None, sequence_length = lookback,\n",
    "                                                            sequence_stride = 1, shuffle = False)\n",
    "for batch in ds:\n",
    "    tmp.append(batch.numpy())\n",
    "test_X=np.vstack(tmp)\n",
    "\n",
    "ds2= tf.keras.preprocessing.timeseries_dataset_from_array(test[:,2,2], targets = None, sequence_length = 1,\n",
    "                                                            sequence_stride = 1, shuffle = False, start_index = lookback)\n",
    "for batch2 in ds2:\n",
    "    tmp2.append(batch2.numpy())\n",
    "test_Y = np.vstack(tmp2)\n",
    "test_X = test_X[0:test_Y.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack parameters\n",
    "x1 = [0, 25, 50, 100, 300] # attack start time\n",
    "duration = [100, 400, 800, 1000] # attack duration  \n",
    "epsilon = [0.01, 0.06, 0.09, 0.2] # fgsm/bim epsilon\n",
    "LEN = len(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7feafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilon:        \n",
    "    for d in (duration):\n",
    "        max_traffic = []\n",
    "        real_traffic = []      \n",
    "        print('duration:', d)\n",
    "        print('epsilon:', eps)           \n",
    "        \n",
    "        FGSM_SLA_NUM = 0\n",
    "        BIM_SLA_NUM = 0\n",
    "        prediction_SLA_NUM = 0\n",
    "        LRP_SLA_NUM = 0  \n",
    "        LRP_least_SLA_NUM = 0\n",
    "\n",
    "        FGSM_OVERPROV_COST = 0\n",
    "        BIM_OVERPROV_COST = 0\n",
    "        prediction_OVERPROV_COST = 0\n",
    "        LRP_OVERPROV_COST = 0  \n",
    "        LRP_least_OVERPROV_COST = 0\n",
    "   \n",
    "        for start in (x1):                         \n",
    "            x2 = start + d   \n",
    "            test_XX = test_X[start:x2,:,:,:]\n",
    "            test_YY = test_Y[start:x2,:]       \n",
    "            # load most/least relevant cell ids\n",
    "            cell_ids = np.load('./cell_ids/'+str(cell)+'_'+str(damage)+'_most_relevant.npy')\n",
    "            cell_ids2 = np.load('./cell_ids/'+str(cell)+'_'+str(damage)+'_least_relevant.npy')\n",
    "\n",
    "            test_YY = np.reshape(test_YY, (test_YY.shape[0],1))\n",
    "            \n",
    "            prediction_conv = nn.predict(test_XX) # predicted \n",
    "            ###################################################################################\n",
    "            # normal FGSM attack\n",
    "            adv_X, _ = fgsm(X = test_XX, Y = test_YY, model = nn , loss_fn = loss_func,\n",
    "                            epsilon = eps, targeted = True)\n",
    "            bim_X, _ = bim(X = test_XX, Y = test_YY, model = nn , loss_fn = loss_func,\n",
    "                            epsilon = eps, alpha2 = 0.001, I = 200, targeted = True)\n",
    "            FGSM = nn.predict(adv_X)\n",
    "            BIM = nn.predict(bim_X)\n",
    "            test_X2 = test_XX.copy()\n",
    "            test_X3 = test_XX.copy()\n",
    "            for element in range(0, len(adv_X)):\n",
    "                traffic_peak = max(test_YY[element])                \n",
    "                for h in range(2,3):\n",
    "                    added_value = 0\n",
    "                    added_value2 = 0\n",
    "                    injected_element = np.sum(adv_X[element,h,:,:] - test_XX[element,h,:,:])\n",
    "                    idx = int(cell_ids[element])\n",
    "                    row = math.floor(idx / 5)\n",
    "                    col = idx % 5\n",
    "                    added_value = injected_element + test_XX[element,h,row,col]\n",
    "                    test_X2[element,h,row,col] = added_value\n",
    "\n",
    "                LRP = nn.predict(test_X2)\n",
    "                ###############################################################################                                             \n",
    "                for h in range(2,3):\n",
    "                    injected_element = np.sum(adv_X[element,h,:,:] - test_XX[element,h,:,:])\n",
    "                    #LRP least: Approach 1 \n",
    "                    idx2 = int(cell_ids2[element])\n",
    "                    row2 = math.floor(idx2 / 5)\n",
    "                    col2 = idx2 % 5\n",
    "                    added_value2 = injected_element + test_XX[element,h,row2,col2]\n",
    "                    test_X3[element,h,row2,col2] = added_value2\n",
    "\n",
    "                LRP_least = nn.predict(test_X3)\n",
    "                ###############################################################################\n",
    "                FGSM_sla_num = sla_num(FGSM[element], test_YY[element])\n",
    "                BIM_sla_num = sla_num(BIM[element], test_YY[element])\n",
    "                prediction_sla_num = sla_num(prediction_conv[element], test_YY[element])\n",
    "                LRP_sla_num = sla_num(LRP[element], test_YY[element])     \n",
    "                LRP_least_sla_num = sla_num(LRP_least[element], test_YY[element])\n",
    "                            \n",
    "                FGSM_overprov_cost = overprov_cost(FGSM[element], test_YY[element], traffic_peak, alpha)\n",
    "                BIM_overprov_cost = overprov_cost(BIM[element], test_YY[element], traffic_peak, alpha)\n",
    "                prediction_overprov_cost = overprov_cost(prediction_conv[element], test_YY[element], traffic_peak, alpha)\n",
    "                LRP_overprov_cost = overprov_cost(LRP[element], test_YY[element], traffic_peak, alpha)     \n",
    "                LRP_least_overprov_cost = overprov_cost(LRP_least[element], test_YY[element], traffic_peak, alpha)\n",
    "\n",
    "                FGSM_SLA_NUM += FGSM_sla_num\n",
    "                BIM_SLA_NUM += BIM_sla_num\n",
    "                prediction_SLA_NUM += prediction_sla_num\n",
    "                LRP_SLA_NUM += LRP_sla_num   \n",
    "                LRP_least_SLA_NUM += LRP_least_sla_num \n",
    "\n",
    "                FGSM_OVERPROV_COST += FGSM_overprov_cost\n",
    "                BIM_OVERPROV_COST += BIM_overprov_cost\n",
    "                prediction_OVERPROV_COST += prediction_overprov_cost\n",
    "                LRP_OVERPROV_COST += LRP_overprov_cost \n",
    "                LRP_least_OVERPROV_COST += LRP_least_overprov_cost\n",
    "\n",
    "        print('')\n",
    "        print('FGSM_SLA_num', (FGSM_SLA_NUM/LEN))\n",
    "        print('BIM_SLA_num', (BIM_SLA_NUM/LEN))\n",
    "        print('LRP_SLA_num', (LRP_SLA_NUM/LEN))\n",
    "        print('LRP_least_SLA_num', (LRP_least_SLA_NUM/LEN))\n",
    "        print('no_attack_SLA_num:', (prediction_SLA_NUM/LEN))\n",
    "        print('')       \n",
    "\n",
    "        print('FGSM_OVERPROV_cost', float(\"{:.2f}\".format((FGSM_OVERPROV_COST/LEN))))\n",
    "        print('BIM_OVERPROV_cost', float(\"{:.2f}\".format((BIM_OVERPROV_COST/LEN))))\n",
    "        print('LRP_OVERPROV_cost', float(\"{:.2f}\".format((LRP_OVERPROV_COST/LEN))))\n",
    "        print('LRP_least_OVERPROV_cost', float(\"{:.2f}\".format((LRP_least_OVERPROV_COST/LEN))))\n",
    "        print('no_attack_OVERPROV_cost:', float(\"{:.2f}\".format((prediction_OVERPROV_COST/LEN))))\n",
    "        print('')\n",
    "        print('-----------------------------------------------------------------------------')\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "46e0c58788f346b266fbc3647b102f93196dbe6ff6400d04c9c4d9ad5d261b93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
